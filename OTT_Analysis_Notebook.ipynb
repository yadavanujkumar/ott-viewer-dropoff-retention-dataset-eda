{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfac OTT Viewer Drop-Off & Retention Dataset - Comprehensive Data Science Analysis\n",
    "\n",
    "This notebook demonstrates comprehensive capabilities in:\n",
    "- **Exploratory Data Analysis (EDA)**\n",
    "- **Machine Learning** (Classification & Regression)\n",
    "- **Feature Engineering**\n",
    "- **Advanced Analytics** (Clustering, Time Series)\n",
    "- **Business Intelligence**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcda Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             mean_squared_error, r2_score, accuracy_score, roc_curve)\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\u2713 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Section 1: Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('ott_viewer_dropoff_retention_us_v1.0.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nTotal Episodes: {len(df):,}\")\n",
    "print(f\"Unique Shows: {df['show_id'].nunique()}\")\n",
    "print(f\"Platforms: {df['platform'].nunique()}\")\n",
    "print(f\"Genres: {df['genre'].nunique()}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"\u2713 No missing values found!\")\n",
    "else:\n",
    "    print(\"Missing values:\\n\", missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Section 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Drop-off distribution\n",
    "df['drop_off'].value_counts().plot(kind='bar', ax=axes[0], color=['green', 'red'])\n",
    "axes[0].set_title('Drop-off Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Drop-off (0=No, 1=Yes)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['No Drop-off', 'Drop-off'], rotation=0)\n",
    "\n",
    "# Retention risk distribution\n",
    "df['retention_risk'].value_counts().plot(kind='bar', ax=axes[1], color=['green', 'orange', 'red'])\n",
    "axes[1].set_title('Retention Risk Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Retention Risk')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Drop-off probability distribution\n",
    "axes[2].hist(df['drop_off_probability'], bins=50, color='steelblue', edgecolor='black')\n",
    "axes[2].set_title('Drop-off Probability Distribution', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Drop-off Probability')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].axvline(df['drop_off_probability'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Drop-off Rate: {df['drop_off'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform and Genre distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Top platforms\n",
    "df['platform'].value_counts().head(10).plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Top 10 Platforms', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Episodes')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Top genres\n",
    "df['genre'].value_counts().head(10).plot(kind='barh', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Top 10 Genres', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Episodes')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key metrics distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "metrics = [\n",
    "    ('avg_watch_percentage', 'Average Watch Percentage'),\n",
    "    ('hook_strength', 'Hook Strength'),\n",
    "    ('pacing_score', 'Pacing Score'),\n",
    "    ('cognitive_load', 'Cognitive Load'),\n",
    "    ('visual_intensity', 'Visual Intensity'),\n",
    "    ('episode_duration_min', 'Episode Duration (min)')\n",
    "]\n",
    "\n",
    "for idx, (col, title) in enumerate(metrics):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.hist(df[col], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd17 Section 3: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for correlation\n",
    "numerical_features = ['pacing_score', 'hook_strength', 'visual_intensity',\n",
    "                     'avg_watch_percentage', 'pause_count', 'rewind_count',\n",
    "                     'cognitive_load', 'episode_duration_min',\n",
    "                     'drop_off', 'drop_off_probability']\n",
    "\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations with target variable\n",
    "drop_off_corr = correlation_matrix['drop_off'].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "drop_off_corr[drop_off_corr.index != 'drop_off'].plot(kind='barh', color='steelblue')\n",
    "plt.title('Feature Correlations with Drop-off', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Section 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for ML",
    "df_ml = df.copy()",
    "",
    "# Episode position features",
    "df_ml['is_premiere'] = (df_ml['episode_number'] == 1).astype(int)",
    "df_ml['is_finale'] = df_ml.groupby(['show_id', 'season_number'])['episode_number'].transform('max') == df_ml['episode_number']",
    "df_ml['is_finale'] = df_ml['is_finale'].astype(int)",
    "df_ml['episode_position'] = df_ml['episode_number'] / df_ml.groupby(['show_id', 'season_number'])['episode_number'].transform('max')",
    "",
    "# Engagement metrics",
    "df_ml['completion_rate'] = df_ml['avg_watch_percentage'] / 100",
    "df_ml['interaction_intensity'] = df_ml['pause_count'] + df_ml['rewind_count']",
    "df_ml['engagement_score'] = (df_ml['avg_watch_percentage'] * df_ml['hook_strength']) / 100",
    "",
    "# Encode categorical variables",
    "le_platform = LabelEncoder()",
    "le_genre = LabelEncoder()",
    "le_attention = LabelEncoder()",
    "le_retention = LabelEncoder()",
    "",
    "df_ml['platform_encoded'] = le_platform.fit_transform(df_ml['platform'])",
    "df_ml['genre_encoded'] = le_genre.fit_transform(df_ml['genre'])",
    "df_ml['attention_encoded'] = le_attention.fit_transform(df_ml['attention_required'])",
    "df_ml['retention_risk_encoded'] = le_retention.fit_transform(df_ml['retention_risk'])",
    "le_dialogue = LabelEncoder()",
    "df_ml['dialogue_density_encoded'] = le_dialogue.fit_transform(df_ml['dialogue_density'])",
    "",
    "# Content complexity (now using encoded dialogue_density)",
    "df_ml['content_complexity'] = (df_ml['cognitive_load'] + df_ml['dialogue_density_encoded'] + df_ml['visual_intensity']) / 3",
    "",
    "print(f\"\u2713 Feature engineering completed!\")",
    "print(f\"Total features: {len(df_ml.columns)}\")",
    "print(f\"\\nNew features created:\")",
    "new_features = [c for c in df_ml.columns if c not in df.columns]",
    "for feat in new_features:",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd16 Section 5: Machine Learning - Binary Classification (Drop-off Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling",
    "feature_cols = ['pacing_score', 'hook_strength', 'visual_intensity',",
    "               'avg_watch_percentage', 'pause_count', 'rewind_count',",
    "               'cognitive_load', 'platform_encoded', 'genre_encoded',",
    "               'attention_encoded', 'dialogue_density_encoded', 'season_number', 'episode_number',",
    "               'is_premiere', 'is_finale', 'episode_position',",
    "               'engagement_score', 'content_complexity', 'skip_intro',",
    "               'night_watch_safe', 'episode_duration_min']",
    "",
    "X = df_ml[feature_cols]",
    "y = df_ml['drop_off']",
    "",
    "# Train-test split",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)",
    "",
    "print(f\"Training samples: {len(X_train):,}\")",
    "print(f\"Test samples: {len(X_test):,}\")",
    "print(f\"Drop-off rate in training: {y_train.mean()*100:.2f}%\")",
    "print(f\"Drop-off rate in test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOM FOREST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['No Drop-off', 'Drop-off']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['No Drop-off', 'Drop-off'],\n",
    "            yticklabels=['No Drop-off', 'Drop-off'])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "axes[1].plot(fpr, tpr, linewidth=2, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_pred_proba_rf):.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Feature Importance - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Section 6: Regression - Drop-off Probability Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression\n",
    "y_reg = df_ml['drop_off_probability']\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting Regressor\n",
    "print(\"Training Gradient Boosting Regressor...\")\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "gb_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = gb_model.predict(X_test_reg)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRADIENT BOOSTING REGRESSION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"R\u00b2 Score: {r2_score(y_test_reg, y_pred_gb):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_pred_gb)):.4f}\")\n",
    "print(f\"MAE: {np.mean(np.abs(y_test_reg - y_pred_gb)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_reg, y_pred_gb, alpha=0.3, s=10)\n",
    "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Drop-off Probability', fontsize=12)\n",
    "plt.ylabel('Predicted Drop-off Probability', fontsize=12)\n",
    "plt.title('Predicted vs Actual Drop-off Probability', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test_reg - y_pred_gb\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_gb, residuals, alpha=0.3, s=10)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Drop-off Probability', fontsize=12)\n",
    "plt.ylabel('Residuals', fontsize=12)\n",
    "plt.title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Section 7: Multi-Class Classification (Retention Risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "y_risk = df_ml['retention_risk_encoded']\n",
    "\n",
    "X_train_risk, X_test_risk, y_train_risk, y_test_risk = train_test_split(\n",
    "    X, y_risk, test_size=0.2, random_state=42, stratify=y_risk\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"Training Random Forest for Retention Risk...\")\n",
    "rf_risk_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_risk_model.fit(X_train_risk, y_train_risk)\n",
    "\n",
    "# Predictions\n",
    "y_pred_risk = rf_risk_model.predict(X_test_risk)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RETENTION RISK CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test_risk, y_pred_risk):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "risk_labels = le_retention.classes_\n",
    "print(classification_report(y_test_risk, y_pred_risk, target_names=risk_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for multi-class\n",
    "cm_risk = confusion_matrix(y_test_risk, y_pred_risk)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_risk, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=risk_labels, yticklabels=risk_labels)\n",
    "plt.title('Retention Risk - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Section 8: Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "cluster_features = ['avg_watch_percentage', 'hook_strength', 'pacing_score',\n",
    "                   'cognitive_load', 'visual_intensity', 'drop_off_probability']\n",
    "\n",
    "X_cluster = df_ml[cluster_features].copy()\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_cluster_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "# K-Means clustering\n",
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "df_ml['cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "print(f\"Clustering completed with {n_clusters} clusters\")\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(df_ml['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster characteristics\n",
    "print(\"\\nCluster Characteristics:\\n\")\n",
    "for i in range(n_clusters):\n",
    "    cluster_data = df_ml[df_ml['cluster'] == i]\n",
    "    print(f\"Cluster {i} ({len(cluster_data)} episodes):\")\n",
    "    print(f\"  Avg Watch %: {cluster_data['avg_watch_percentage'].mean():.1f}%\")\n",
    "    print(f\"  Drop-off Rate: {cluster_data['drop_off'].mean()*100:.1f}%\")\n",
    "    print(f\"  Hook Strength: {cluster_data['hook_strength'].mean():.2f}\")\n",
    "    print(f\"  Cognitive Load: {cluster_data['cognitive_load'].mean():.2f}\")\n",
    "    print(f\"  Dominant Risk: {cluster_data['retention_risk'].mode()[0]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Cluster scatter plot\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = df_ml[df_ml['cluster'] == cluster]\n",
    "    axes[0].scatter(cluster_data['avg_watch_percentage'],\n",
    "                   cluster_data['drop_off_probability'],\n",
    "                   label=f'Cluster {cluster}', alpha=0.5, s=10)\n",
    "\n",
    "axes[0].set_xlabel('Average Watch Percentage', fontsize=12)\n",
    "axes[0].set_ylabel('Drop-off Probability', fontsize=12)\n",
    "axes[0].set_title('Clusters: Watch % vs Drop-off Probability', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Cluster profiles\n",
    "cluster_profiles = df_ml.groupby('cluster')[cluster_features].mean()\n",
    "cluster_profiles_normalized = (cluster_profiles - cluster_profiles.min()) / (cluster_profiles.max() - cluster_profiles.min())\n",
    "cluster_profiles_normalized.T.plot(kind='bar', ax=axes[1], width=0.8)\n",
    "axes[1].set_title('Normalized Cluster Profiles', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Normalized Value')\n",
    "axes[1].set_xlabel('Features')\n",
    "axes[1].legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc9 Section 9: Time Series Analysis - Episode Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode-level analysis\n",
    "episode_analysis = df_ml.groupby('episode_number').agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'drop_off_probability': 'mean',\n",
    "    'show_id': 'count'\n",
    "}).rename(columns={'show_id': 'episode_count'})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Drop-off by episode\n",
    "axes[0].plot(episode_analysis.index, episode_analysis['drop_off']*100, marker='o', linewidth=2)\n",
    "axes[0].set_xlabel('Episode Number', fontsize=12)\n",
    "axes[0].set_ylabel('Drop-off Rate (%)', fontsize=12)\n",
    "axes[0].set_title('Drop-off Rate by Episode Number', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Watch percentage by episode\n",
    "axes[1].plot(episode_analysis.index, episode_analysis['avg_watch_percentage'], marker='o', color='green', linewidth=2)\n",
    "axes[1].set_xlabel('Episode Number', fontsize=12)\n",
    "axes[1].set_ylabel('Average Watch Percentage', fontsize=12)\n",
    "axes[1].set_title('Watch Completion by Episode Number', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Episode-level trends:\")\n",
    "print(episode_analysis.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season-level analysis\n",
    "season_analysis = df_ml.groupby('season_number').agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'drop_off_probability': 'mean',\n",
    "    'show_id': 'count'\n",
    "}).rename(columns={'show_id': 'episode_count'})\n",
    "\n",
    "print(\"\\nSeason-level trends:\")\n",
    "print(season_analysis)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = season_analysis.index\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, season_analysis['drop_off']*100, width, label='Drop-off Rate (%)', color='red', alpha=0.7)\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(x + width/2, season_analysis['avg_watch_percentage'], width, label='Avg Watch %', color='green', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Season Number', fontsize=12)\n",
    "ax.set_ylabel('Drop-off Rate (%)', fontsize=12)\n",
    "ax2.set_ylabel('Average Watch Percentage', fontsize=12)\n",
    "ax.set_title('Season-level Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premiere vs Regular vs Finale comparison\n",
    "premiere_stats = df_ml[df_ml['is_premiere'] == 1].agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'drop_off_probability': 'mean'\n",
    "})\n",
    "\n",
    "finale_stats = df_ml[df_ml['is_finale'] == 1].agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'drop_off_probability': 'mean'\n",
    "})\n",
    "\n",
    "regular_stats = df_ml[(df_ml['is_premiere'] == 0) & (df_ml['is_finale'] == 0)].agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'drop_off_probability': 'mean'\n",
    "})\n",
    "\n",
    "# Create comparison dataframe\n",
    "episode_type_comparison = pd.DataFrame({\n",
    "    'Premiere': premiere_stats,\n",
    "    'Regular': regular_stats,\n",
    "    'Finale': finale_stats\n",
    "})\n",
    "\n",
    "print(\"\\nPremiere vs Regular vs Finale Episodes:\")\n",
    "print(episode_type_comparison)\n",
    "\n",
    "# Visualize\n",
    "episode_type_comparison.T.plot(kind='bar', figsize=(12, 6), rot=0)\n",
    "plt.title('Performance Metrics by Episode Type', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Episode Type')\n",
    "plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udca1 Section 10: Business Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-risk episodes analysis\n",
    "high_risk_episodes = df_ml[df_ml['retention_risk'] == 'high']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HIGH-RISK EPISODES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal high-risk episodes: {len(high_risk_episodes):,}\")\n",
    "print(f\"Percentage of dataset: {len(high_risk_episodes)/len(df_ml)*100:.1f}%\")\n",
    "print(f\"\\nCharacteristics:\")\n",
    "print(f\"  Average watch completion: {high_risk_episodes['avg_watch_percentage'].mean():.1f}%\")\n",
    "print(f\"  Average cognitive load: {high_risk_episodes['cognitive_load'].mean():.2f}\")\n",
    "print(f\"  Average hook strength: {high_risk_episodes['hook_strength'].mean():.2f}\")\n",
    "print(f\"  Average pacing score: {high_risk_episodes['pacing_score'].mean():.2f}\")\n",
    "print(f\"\\nTop genres at risk:\")\n",
    "print(high_risk_episodes['genre'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Night-watch analysis\n",
    "night_safe = df_ml[df_ml['night_watch_safe'] == 1]\n",
    "not_night_safe = df_ml[df_ml['night_watch_safe'] == 0]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NIGHT-WATCH SAFETY IMPACT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNight-safe episodes: {len(night_safe):,} ({len(night_safe)/len(df_ml)*100:.1f}%)\")\n",
    "print(f\"Not night-safe episodes: {len(not_night_safe):,} ({len(not_night_safe)/len(df_ml)*100:.1f}%)\")\n",
    "print(f\"\\nDrop-off rates:\")\n",
    "print(f\"  Night-safe: {night_safe['drop_off'].mean()*100:.2f}%\")\n",
    "print(f\"  Not night-safe: {not_night_safe['drop_off'].mean()*100:.2f}%\")\n",
    "print(f\"  Difference: {(not_night_safe['drop_off'].mean() - night_safe['drop_off'].mean())*100:.2f} percentage points\")\n",
    "\n",
    "# Visualize\n",
    "night_comparison = pd.DataFrame({\n",
    "    'Night-safe': [night_safe['drop_off'].mean()*100, night_safe['avg_watch_percentage'].mean()],\n",
    "    'Not Night-safe': [not_night_safe['drop_off'].mean()*100, not_night_safe['avg_watch_percentage'].mean()]\n",
    "}, index=['Drop-off Rate (%)', 'Avg Watch (%)'])\n",
    "\n",
    "night_comparison.T.plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "plt.title('Night-Watch Safety Impact on Viewer Behavior', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Percentage')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend(title='Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform performance\n",
    "print(\"=\"*60)\n",
    "print(\"PLATFORM PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "platform_perf = df_ml.groupby('platform').agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'show_id': 'nunique',\n",
    "    'title': 'count'\n",
    "}).sort_values('avg_watch_percentage', ascending=False).head(10)\n",
    "platform_perf.columns = ['Drop-off Rate', 'Avg Watch %', 'Unique Shows', 'Total Episodes']\n",
    "\n",
    "print(\"\\nTop 10 Platforms by Average Watch Percentage:\")\n",
    "print(platform_perf)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "platform_perf['Avg Watch %'].plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Average Watch % by Platform (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Average Watch Percentage')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "platform_perf['Drop-off Rate'].plot(kind='barh', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Drop-off Rate by Platform (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Drop-off Rate')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre performance\n",
    "print(\"=\"*60)\n",
    "print(\"GENRE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "genre_perf = df_ml.groupby('genre').agg({\n",
    "    'drop_off': 'mean',\n",
    "    'avg_watch_percentage': 'mean',\n",
    "    'show_id': 'nunique',\n",
    "    'title': 'count'\n",
    "}).sort_values('avg_watch_percentage', ascending=False).head(10)\n",
    "genre_perf.columns = ['Drop-off Rate', 'Avg Watch %', 'Unique Shows', 'Total Episodes']\n",
    "\n",
    "print(\"\\nTop 10 Genres by Average Watch Percentage:\")\n",
    "print(genre_perf)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "genre_perf['Avg Watch %'].plot(kind='barh', ax=axes[0], color='green')\n",
    "axes[0].set_title('Average Watch % by Genre (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Average Watch Percentage')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "genre_perf['Drop-off Rate'].plot(kind='barh', ax=axes[1], color='red')\n",
    "axes[1].set_title('Drop-off Rate by Genre (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Drop-off Rate')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Section 11: Final Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\u2705 ANALYSES COMPLETED:\")\n",
    "print(\"   \u2713 Exploratory Data Analysis (EDA)\")\n",
    "print(\"   \u2713 Feature Engineering (13 new features)\")\n",
    "print(\"   \u2713 Binary Classification (Drop-off Prediction)\")\n",
    "print(\"   \u2713 Multi-class Classification (Retention Risk)\")\n",
    "print(\"   \u2713 Regression (Drop-off Probability)\")\n",
    "print(\"   \u2713 Clustering Analysis (4 viewer segments)\")\n",
    "print(\"   \u2713 Time Series Analysis (Episode/Season trends)\")\n",
    "print(\"   \u2713 Business Intelligence Insights\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca MODEL PERFORMANCE:\")\n",
    "print(f\"   \u2022 Drop-off Prediction (Random Forest):\")\n",
    "print(f\"     - Accuracy: {accuracy_score(y_test, y_pred_rf):.1%}\")\n",
    "print(f\"     - ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.3f}\")\n",
    "print(f\"   \u2022 Probability Prediction (Gradient Boosting):\")\n",
    "print(f\"     - R\u00b2 Score: {r2_score(y_test_reg, y_pred_gb):.3f}\")\n",
    "print(f\"     - RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_pred_gb)):.4f}\")\n",
    "print(f\"   \u2022 Retention Risk (Random Forest):\")\n",
    "print(f\"     - Accuracy: {accuracy_score(y_test_risk, y_pred_risk):.1%}\")\n",
    "\n",
    "print(\"\\n\ud83c\udfaf KEY INSIGHTS:\")\n",
    "print(f\"   \u2022 Overall drop-off rate: {df['drop_off'].mean()*100:.2f}%\")\n",
    "print(f\"   \u2022 High-risk episodes: {len(high_risk_episodes):,} ({len(high_risk_episodes)/len(df)*100:.1f}%)\")\n",
    "print(f\"   \u2022 Top predictor of drop-off: {feature_importance.iloc[0]['feature']}\")\n",
    "print(f\"   \u2022 Night-watch safety reduces drop-off by {(not_night_safe['drop_off'].mean() - night_safe['drop_off'].mean())*100:.2f}pp\")\n",
    "print(f\"   \u2022 Episode 1 (premieres) have {df_ml[df_ml['is_premiere']==1]['drop_off'].mean()*100:.1f}% drop-off rate\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 RECOMMENDATIONS FOR OTT PLATFORMS:\")\n",
    "print(\"\"\"   \n",
    "   1. CONTENT OPTIMIZATION:\n",
    "      \u2022 Improve hook strength in high-risk episodes\n",
    "      \u2022 Balance cognitive load to avoid viewer fatigue\n",
    "      \u2022 Optimize pacing for better engagement\n",
    "   \n",
    "   2. STRATEGIC POSITIONING:\n",
    "      \u2022 Create night-watch-safe content playlists\n",
    "      \u2022 Pay attention to mid-season drop-off patterns\n",
    "      \u2022 Strengthen premieres and finales\n",
    "   \n",
    "   3. PREDICTIVE ANALYTICS:\n",
    "      \u2022 Deploy ML models for real-time churn prediction\n",
    "      \u2022 Implement early warning systems for at-risk viewers\n",
    "      \u2022 Use clustering for personalized recommendations\n",
    "   \n",
    "   4. PLATFORM-SPECIFIC:\n",
    "      \u2022 Benchmark against top-performing platforms\n",
    "      \u2022 Genre-specific retention strategies\n",
    "      \u2022 A/B test content positioning\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\ud83d\ude80 NEXT STEPS:\")\n",
    "print(\"\"\"   \n",
    "   \u2022 Deploy models in production environment\n",
    "   \u2022 Set up real-time monitoring dashboards\n",
    "   \u2022 Conduct A/B experiments on recommendations\n",
    "   \u2022 Deep-dive into show-specific patterns\n",
    "   \u2022 Integrate with existing analytics pipelines\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Analysis Complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}