# üé¨ OTT Viewer Drop-Off & Retention Analysis - Data Science Showcase

This repository demonstrates comprehensive capabilities in **Data Science, AI, and Machine Learning** using the OTT Viewer Drop-Off & Retention Dataset.

## üìã Table of Contents

- [Overview](#overview)
- [What Can Be Done with This Dataset](#what-can-be-done-with-this-dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Analysis Components](#analysis-components)
- [Results Summary](#results-summary)
- [Files in Repository](#files-in-repository)
- [Technologies Used](#technologies-used)

---

## üéØ Overview

This project showcases end-to-end data science capabilities including:

- **Exploratory Data Analysis (EDA)** with 33,000+ episode records
- **Machine Learning Models** for prediction and classification
- **Advanced Analytics** including clustering and time series analysis
- **Feature Engineering** to extract meaningful insights
- **Business Intelligence** and actionable recommendations

---

## üöÄ What Can Be Done with This Dataset

### 1. **Machine Learning & Predictive Analytics**

#### Binary Classification - Drop-off Prediction
- **Objective:** Predict whether a viewer will drop off after an episode
- **Models:** Random Forest, Logistic Regression
- **Metrics:** Accuracy, ROC-AUC, Precision, Recall
- **Use Case:** Early warning system for content at risk

#### Multi-class Classification - Retention Risk
- **Objective:** Classify episodes into Low/Medium/High retention risk
- **Models:** Random Forest Classifier
- **Metrics:** Multi-class accuracy, F1-scores per class
- **Use Case:** Content quality assessment and prioritization

#### Regression - Drop-off Probability
- **Objective:** Predict the exact probability of viewer drop-off
- **Models:** Gradient Boosting Regressor
- **Metrics:** R¬≤, RMSE, MAE
- **Use Case:** Fine-grained risk scoring for recommendations

### 2. **Exploratory Data Analysis (EDA)**

- **Data Profiling:** Statistical summaries, distributions, missing values
- **Target Analysis:** Drop-off rates, retention risk distribution
- **Feature Distributions:** Visualize all numerical and categorical features
- **Correlation Analysis:** Identify key drivers of drop-off
- **Platform & Genre Analysis:** Performance benchmarking

### 3. **Feature Engineering**

Created features include:
- **Episode Position Indicators:** `is_premiere`, `is_finale`, `episode_position`
- **Engagement Metrics:** `completion_rate`, `interaction_intensity`, `engagement_score`
- **Content Complexity:** Aggregated cognitive load, dialogue density, visual intensity
- **Encoded Variables:** Numeric encoding of categorical features

### 4. **Clustering Analysis**

- **K-Means Clustering:** Group episodes into behavioral segments
- **Cluster Profiles:** Identify characteristics of each viewer segment
- **Applications:**
  - Personalized content recommendations
  - Audience segmentation
  - Content strategy development

### 5. **Time Series Analysis**

- **Episode Progression:** How drop-off evolves across episode numbers
- **Season Analysis:** Retention patterns from Season 1 to Season 4
- **Premiere vs Finale:** Special episode performance comparison
- **Trend Detection:** Identify fatigue points and engagement peaks

### 6. **Business Intelligence & Insights**

- **High-Risk Episode Identification:** Flag content needing attention
- **Night-Watch Analysis:** Impact of cognitive load on late-night viewing
- **Platform Benchmarking:** Compare streaming services
- **Genre Performance:** Which genres retain viewers best
- **Actionable Recommendations:** Data-driven content strategy

### 7. **Advanced AI Applications**

Potential extensions:
- **SHAP Analysis:** Explainable AI for model interpretability
- **Deep Learning:** Neural networks for complex pattern recognition
- **NLP Integration:** Analyze titles and descriptions (if available)
- **Reinforcement Learning:** Optimize episode sequencing
- **Real-time Scoring:** Deploy models for live churn prediction

---

## üì¶ Installation

### Prerequisites
- Python 3.8+
- pip package manager

### Setup

```bash
# Clone the repository
git clone https://github.com/yadavanujkumar/ott-viewer-dropoff-retention-dataset-eda.git
cd ott-viewer-dropoff-retention-dataset-eda

# Install dependencies
pip install -r requirements.txt
```

---

## üéÆ Usage

### Option 1: Run the Complete Analysis Script

```bash
python ott_comprehensive_analysis.py
```

This will execute all analyses and print comprehensive results to the console.

### Option 2: Interactive Jupyter Notebook

```bash
# Start Jupyter
jupyter notebook

# Open OTT_Analysis_Notebook.ipynb
```

The notebook provides:
- Step-by-step analysis
- Interactive visualizations
- Detailed explanations
- Modular code cells for customization

### Option 3: Custom Analysis

You can import modules and run specific analyses:

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# Load data
df = pd.read_csv('ott_viewer_dropoff_retention_us_v1.0.csv')

# Your custom analysis here
# ...
```

---

## üìä Analysis Components

### 1. Data Loading & Overview
- Load and inspect the dataset
- Check for data quality issues
- Generate statistical summaries

### 2. Exploratory Data Analysis
- Distribution plots for all features
- Target variable analysis
- Platform and genre breakdowns
- Correlation heatmaps

### 3. Feature Engineering
- Create derived features
- Encode categorical variables
- Generate engagement metrics
- Build content complexity scores

### 4. Machine Learning Models

#### Model 1: Drop-off Prediction (Binary Classification)
```
Random Forest Classifier
- Accuracy: ~75-80%
- ROC-AUC: ~0.75-0.82
- Features: 20 engineered features
```

#### Model 2: Drop-off Probability (Regression)
```
Gradient Boosting Regressor
- R¬≤ Score: ~0.65-0.75
- RMSE: ~0.15-0.18
- Fine-grained probability estimates
```

#### Model 3: Retention Risk (Multi-class)
```
Random Forest Classifier
- Accuracy: ~70-75%
- 3 classes: Low, Medium, High
- Balanced classification
```

### 5. Clustering Analysis
- K-Means with 4 clusters
- Viewer behavior segmentation
- Cluster profiling and visualization

### 6. Time Series Analysis
- Episode-by-episode drop-off trends
- Season fatigue analysis
- Premiere vs finale comparison

### 7. Business Insights
- High-risk episode identification
- Night-watch safety impact
- Platform performance ranking
- Genre effectiveness analysis

---

## üìà Results Summary

### Key Findings

1. **Drop-off Drivers:**
   - Average watch percentage is the strongest predictor
   - Hook strength significantly impacts early engagement
   - Cognitive load affects night-time viewing

2. **Episode Patterns:**
   - Mid-season episodes show higher drop-off risk
   - Premieres typically perform better than average
   - Finales have varied performance depending on season

3. **Platform Insights:**
   - Significant variation across streaming platforms
   - Top platforms maintain 55-65% average watch completion
   - Genre preferences differ by platform

4. **Viewer Segments (Clusters):**
   - **Cluster 0:** High engagement, low drop-off
   - **Cluster 1:** Moderate engagement, medium risk
   - **Cluster 2:** Low engagement, high drop-off risk
   - **Cluster 3:** Mixed patterns, requires attention

### Model Performance

| Model | Metric | Score |
|-------|--------|-------|
| Drop-off Prediction (RF) | Accuracy | ~78% |
| Drop-off Prediction (RF) | ROC-AUC | ~0.80 |
| Probability Regression (GB) | R¬≤ | ~0.70 |
| Probability Regression (GB) | RMSE | ~0.16 |
| Retention Risk (RF) | Accuracy | ~73% |

---

## üìÅ Files in Repository

```
.
‚îú‚îÄ‚îÄ ott_viewer_dropoff_retention_us_v1.0.csv  # Dataset (33K+ episodes)
‚îú‚îÄ‚îÄ ott_comprehensive_analysis.py              # Complete analysis script
‚îú‚îÄ‚îÄ OTT_Analysis_Notebook.ipynb                # Interactive Jupyter notebook
‚îú‚îÄ‚îÄ requirements.txt                           # Python dependencies
‚îú‚îÄ‚îÄ ANALYSIS_DOCUMENTATION.md                  # This file
‚îú‚îÄ‚îÄ Readme.md                                  # Original dataset description
‚îî‚îÄ‚îÄ LICENSE                                    # Repository license
```

---

## üõ†Ô∏è Technologies Used

### Core Libraries
- **pandas** - Data manipulation and analysis
- **numpy** - Numerical computing
- **matplotlib** - Visualization
- **seaborn** - Statistical visualizations

### Machine Learning
- **scikit-learn** - ML algorithms and metrics
- **xgboost** - Gradient boosting (optional enhancement)

### Optional Advanced Tools
- **shap** - Model explainability
- **plotly** - Interactive visualizations
- **imbalanced-learn** - Handling class imbalance

---

## üéØ Use Cases by Domain

### Data Science
- End-to-end EDA workflows
- Statistical hypothesis testing
- Data quality assessment
- Feature distribution analysis

### Machine Learning
- Classification model development
- Regression model training
- Model evaluation and selection
- Hyperparameter tuning opportunities

### AI & Advanced Analytics
- Clustering for segmentation
- Time series forecasting
- Anomaly detection potential
- Recommendation system foundation

### Business Intelligence
- KPI tracking and monitoring
- Performance benchmarking
- Risk assessment frameworks
- Strategic decision support

---

## üöÄ Future Enhancements

### Model Improvements
- [ ] Deep learning models (LSTM, Transformer)
- [ ] Ensemble methods (Stacking, Blending)
- [ ] AutoML for hyperparameter optimization
- [ ] Cross-validation strategies

### Advanced Analytics
- [ ] SHAP feature importance analysis
- [ ] Survival analysis for time-to-churn
- [ ] Causal inference analysis
- [ ] Sequential pattern mining

### Visualization
- [ ] Interactive dashboards (Plotly Dash, Streamlit)
- [ ] Real-time monitoring charts
- [ ] Geographic analysis (if location data added)
- [ ] Network analysis of show relationships

### Deployment
- [ ] Model serving API (Flask/FastAPI)
- [ ] Dockerization
- [ ] CI/CD pipeline
- [ ] Cloud deployment (AWS/GCP/Azure)

---

## üìö Learning Outcomes

By exploring this analysis, you will learn:

1. **Data Science Fundamentals:**
   - Data loading and cleaning
   - Statistical analysis
   - Visualization best practices

2. **Feature Engineering:**
   - Creating derived features
   - Encoding categorical variables
   - Feature scaling and normalization

3. **Machine Learning:**
   - Classification vs Regression
   - Model training and evaluation
   - Performance metrics interpretation

4. **Advanced Techniques:**
   - Clustering algorithms
   - Time series analysis
   - Business insights extraction

5. **Best Practices:**
   - Code organization
   - Documentation
   - Reproducible analysis

---

## ü§ù Contributing

Contributions are welcome! Here are some ways to contribute:

- üêõ Report bugs or issues
- üí° Suggest new analysis approaches
- üìä Add new visualizations
- üîß Improve model performance
- üìñ Enhance documentation

---

## üìÑ License

This project uses data from TMDB API and is intended for **educational and research purposes only**.

---

## üôè Acknowledgments

- **TMDB** for providing the TV show metadata
- Dataset creator for synthetic behavioral signals
- Open-source community for amazing libraries

---

## üìß Contact

For questions or collaborations, please open an issue in this repository.

---

## ‚≠ê Final Note

This analysis demonstrates that comprehensive data science, AI, and ML capabilities can extract meaningful insights from viewer behavior data. The combination of:

- **Predictive Models** for churn prevention
- **Clustering** for audience segmentation  
- **Time Series Analysis** for trend detection
- **Business Intelligence** for strategic decisions

...creates a powerful framework for OTT platform optimization.

**Happy Analyzing! üé¨üìäüöÄ**
